{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##设备及工作目录信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看CPU及显卡相关信息\n",
    "import psutil\n",
    "import multiprocessing\n",
    "\n",
    "!nvidia-smi#查看显卡信息\n",
    "print(u\"CPU内核数量为\",psutil.cpu_count(False))\n",
    "print(u\"CPU线程数量为\",multiprocessing.cpu_count())\n",
    "print(u'电脑总内存为 %.4f GB' % (psutil.virtual_memory().total / 1024 / 1024 / 1024) )\n",
    "print(u'当前使用的总内存占比为 ',psutil.virtual_memory().percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "\n",
    "print(os.getcwd())#获取当前工作目录路径\n",
    "print(os.path.abspath('.')) #获取当前工作目录路径\n",
    "# print os.path.abspath('test.txt') #获取当前目录文件下的工作目录路径\n",
    "print(os.path.abspath('..')) #获取当前工作的父目录 ！注意是父目录路径\n",
    "print(os.path.abspath(os.curdir))#获取当前工作目录路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##加载必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##加载分析必要的包\n",
    "# coding: utf-8\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import pandas_profiling as pp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import entropy\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import datetime\n",
    "import time\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#记录当前日期用于输出文件命名\n",
    "nowtime = datetime.date.today()\n",
    "nowtime = str(nowtime)[-5:]\n",
    "print(nowtime)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##数据诊断结果\n",
    "\n",
    "###Pandas Profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data为待分析数据\n",
    "report = pp.ProfileReport(data)\n",
    "report.to_file('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Sweetviz\n",
    "\n",
    "可以设置目标标量，将变量和目标变量进行关联分析\n",
    "优势不在于单个数据集上的EDA报告，而在于数据集的比较\n",
    "可以通过两种方式比较数据集：将其拆分（例如训练和测试数据集），或者使用一些过滤器对总体进行细分\n",
    "\n",
    "优势：\n",
    "分析有关目标值的数据集的能力\n",
    "两个数据集之间的比较能力\n",
    "劣势：\n",
    "变量之间没有可视化，如散点图\n",
    "报告在另一个标签中打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sweetviz\n",
    "import sweetviz as sv\n",
    "#data为待分析数据\n",
    "# 可以选择目标特征\n",
    "my_report = sv.analyze(data, target_feat ='data')\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PandasGUI\n",
    "不会生成报告，而是生成一个GUI（图形用户界面）的数据框, 可以做很多事情，比如过滤、统计信息、在变量之间创建图表、以及重塑数据。这些操作可以根据需求拖动选项卡来完成。\n",
    "可以通过创建新的数据透视表或者融合数据集来进行重塑，处理好的数据集可以直接导出成csv\n",
    "优势：\n",
    "可以拖拽\n",
    "快速过滤数据\n",
    "快速绘图\n",
    "缺点：\n",
    "没有完整的统计信息\n",
    "不能生成报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandasgui\n",
    "from pandasgui import show\n",
    "# 部署GUI的数据集\n",
    "gui = show(mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##IPywidgets\n",
    "交互式控件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset('mpg')\n",
    "mpg.head()\n",
    "#交互式示例\n",
    "@interact\n",
    "def show_articles_more_than(column =['horsepower','displacement'],x = [150,300]):\n",
    "    return mpg.loc [mpg [column]> x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##编码方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding  标签编码\n",
    "def labelEncoder_df(df, features):\n",
    "    for i in features:\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        df[i] = encoder.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Mean Encoding 高基数无序特征进行均值编码\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg([('mean', 'mean'), ('beta', 'size'),])\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target,\n",
    "                        self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None,\n",
    "                        self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
